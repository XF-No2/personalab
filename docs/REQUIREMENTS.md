# PersonaLab 需求文档

**文档版本**: v1.0
**创建日期**: 2025-10-14
**最后更新**: 2025-10-14

---

## 项目定位

PersonaLab是一个AI角色对话平台，类似Silly Tavern系统。支持用户与AI角色进行长篇、高一致性、角色可成长的互动叙事体验。

---

## 基本概念

### 角色（Character）
角色定义存储在全局角色库中，包含角色的基础信息（名称、描述、头像）和初始人格设定。一个角色可以被多个故事线使用，在不同故事线中的状态完全独立。

### 背景（Background）
背景定义存储在全局背景库中，包含世界观设定和主线剧情节点。主线剧情是预定义的剧情序列（例如10个节点），提供故事发展的整体方向。

### 故事线（Storyline）
故事线是一条独立的故事世界，由用户选择一个角色和一个背景创建。角色在这个故事线中的状态（人格变化、关系发展等）属于这个故事线，与其他故事线完全隔离。一个故事线内可以有多个会话，支持暂停和继续。

**示例**：
- 故事线A：角色Alserqi + 废土世界 → 发展成盟友关系
- 故事线B：同一个Alserqi + 废土世界 → 发展成敌对关系
- 两条故事线互不影响

---

## 核心需求

### 需求1：主线剧情的执行与遵守

**问题**：
- AI执行主线不完整：背景设定中定义了10个剧情节点，AI执行到第3个就不继续
- AI自主编创偏离主线：AI经常编造与主线无关的剧情，导致故事发展与预期不符

**期望**：
- AI能持续按照主线剧情节点推进故事
- AI自主编创时保持在主线框架内，允许灵活发挥但不能完全偏离

**现实约束**：
- 承认AI无法100%自动遵守主线
- 用户需要在输入框中临时干预剧情
- 系统应尽可能提高AI遵守主线的概率

**设计方案**：
- 将全部主线剧情节点（10个）放入Prompt头部4K区域
- 使用JSON格式呈现，提升在头部的权重
- 利用头部高权重特性，对AI形成全局约束

### 需求2：人格的丰富性与成长

**问题**：
- 人格过于简单：角色人格扁平，缺乏内在冲突和复杂性，行为模式单一
- 人格缺乏成长：角色人格在长对话中保持静态，重要事件后没有相应成长
- AI处理能力有限：人格维度过多时AI表现混乱、自相矛盾

**期望**：
- 角色人格丰富、有深度、有内在冲突
- 角色人格能随剧情发展而成长和变化
- 在AI处理能力约束下，实现尽可能丰富的人格表现

**AI处理能力上限**（根据经验）：
- 二元对立（如：爱/恨）最多3组
- 三元张力（如：忠诚/背叛/中立）最多2组

**设计方案**（借鉴Letta/MemGPT的记忆架构）：
- **Core Memory（核心记忆）**：存储角色当前完整的人格画像，放入Prompt头部4K区域，使用JSON格式
  - 包含：当前人格描述、核心特质、当前目标、关系状态、当前情绪和身体状态
  - 这是对角色当前状态的整体描述，不是分散的字段
  - 每N轮对话触发定期维护任务，使用LLM整合"旧Core Memory + 最近N轮对话 + 状态变化事件"重新生成完整的Core Memory
- **Archival Memory（归档记忆）**：存储历史人格变化事件，使用向量数据库（Chroma）
  - 只在角色状态发生变化时写入事件
  - 异步写入，不阻塞响应
- **Recall Memory（工作记忆）**：最近对话历史，放入Prompt中间区域（4K-32K）
- 人格复杂度控制在AI处理能力范围内（二元对立3组/三元张力2组）

### 需求3：长会话与跨会话的延续性

**问题**：
- 长会话失忆：对话几百轮后，AI遗忘早期重要信息和人格设定
- 跨会话失忆：暂停后再继续时，AI忘记之前会话的角色状态和事件

**期望**：
- 角色能记住历史上发生的重要事件
- 角色状态在长会话和跨会话中保持连贯
- 当用户提到历史事件时，AI能够回忆起来

**技术挑战**：
- AI的上下文窗口有限，无法把所有历史对话都放入上下文

**设计方案**（基于向量数据库RAG，优化Silly Tavern的世界书机制）：
- 使用向量数据库（Chroma）存储历史事件，支持语义检索
- **检索触发机制**（Conversational RAG）：
  - 使用LLM将"当前用户输入 + 最近5-10条对话历史"重新表述为独立的查询语句（Query Contextualization）
  - 用这个独立查询进行向量检索，获取20条相关历史事件
  - 相比世界书的关键词匹配，语义检索不需要精确命中关键词
  - 覆盖范围与世界书相同（考虑对话上下文），但检索方式更智能
- 检索结果放入Prompt的32K+区域（扩展区域）
  - 该区域AI能看到事实信息，但语义分析能力较弱
  - 适合放置大量历史事件供AI参考
- 检索时必须过滤storyline_id，避免不同故事线的事件混淆
- 跨会话延续：新会话加载故事线的Core Memory和历史事件，状态自动延续

---

## 功能需求

### 角色管理
- 创建角色：定义名称、描述、头像、初始人格设定
- 查看、编辑、删除角色

### 背景管理
- 创建背景：定义世界观、世界规则、初始场景、主线剧情节点
- 查看、编辑、删除背景

### 故事线管理
- 创建故事线：选择角色和背景，初始化角色状态
- 查看故事线列表：显示标题、角色、背景、时间信息
- 继续故事线：加载历史状态，继续对话
- 删除故事线

### 对话功能
- 发送消息：用户输入内容（对话、剧情推动、世界描述、干预指令）
- 接收消息：AI生成角色反应和叙事，流式显示
- 查看历史对话

---

## 技术约束与对应设计

### LLM上下文窗口有限
**约束**：无法将所有历史对话都放入上下文，需要技术手段选择性加载历史信息。

**应对**：使用向量数据库RAG检索历史事件，Core Memory存储当前状态。

### LLM注意力机制的U型特点
**约束**：
- 头部0-4K和尾部4K信息权重较高
- 中间4K-32K信息权重中等
- 32K+区域能看到事实，但语义分析能力较弱
- 当上下文很长时，尾部信息的高权重会淹没头部信息

**应对**（Prompt区域分配策略）：
- **头部0-4K**：系统指令 + Core Memory（完整人格画像）+ 全部主线剧情，使用JSON格式提升权重
- **中间4K-32K**：背景世界观 + 最近对话（Recall Memory）
- **32K+区域**：RAG检索的20条历史事件（Archival Memory）
- **尾部4K**：用户最新输入

### LLM处理复杂人格能力有限
**约束**：超过能力上限（二元对立3组/三元张力2组）时，AI表现会混乱。

**应对**：Core Memory中的人格描述控制在该复杂度范围内。

### LLM生成的不可控性
**约束**：LLM是生成式模型，无法100%控制输出，只能提高遵守概率。

**应对**：通过头部JSON格式的强约束提高遵守概率，接受用户需要临时干预的现实。

### 响应时间要求
**约束**：总响应时间应控制在30秒以内。

**应对**：
- 使用流式输出改善等待体验
- 异步并行加载（Core Memory、历史事件、最近对话）
- 事件写入异步执行，不阻塞响应
- RAG检索设置超时保护

### 定期维护机制
**设计**：统一的定期维护任务入口，每10轮触发
- 使用LLM整合"旧Core Memory + 最近10轮对话 + 状态变化事件"重新生成完整的Core Memory
- 清理Recall Memory（保留最近20轮对话）
- 其他维护任务统一管理

---

**文档结束**
