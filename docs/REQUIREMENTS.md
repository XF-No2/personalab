# PersonaLab 需求文档

**文档版本**: v3.0
**创建日期**: 2025-10-14
**最后更新**: 2025-10-16
**状态**: ✅ 已精简（去除设计细节）

---

## 项目定位

PersonaLab是一个AI角色对话平台，类似Silly Tavern系统。支持用户与AI角色进行长篇、高一致性、角色可成长的互动叙事体验。

---

## 基本概念

### 角色（Character）

**定义**：存储在全局角色库中的角色模板，包含：
- 基础信息：名称、描述、头像
- 初始人格设定：性格特征、背景故事、核心动机

**特性**：
- 一个角色可以被多个会话实例使用
- 在不同会话实例中的状态完全独立

### 背景（Background）

**定义**：存储在全局背景库中的故事设定，包含：
- **世界设定**：世界观描述、世界规则、初始场景（一段完整的文字描述）
- **故事主线大纲**：关键剧情点（数量灵活，可以是5个、10个或更多），提供故事发展的建议路线

**示例**：
```
背景名称：废土复仇记

世界设定：
核战后的废土世界，资源匮乏，强者为王。幸存者聚集在几个主要据点，
帮派之间争夺控制权。你是一个被背叛的前帮派老大，现在要复仇。

故事主线大纲：
1. 发现背叛者的线索
2. 潜入敌人据点
3. 与仇人对峙
4. 做出关键选择（杀/放/合作）
5. 应对选择的后果
...（共10个关键点）
```

### 会话实例（Conversation Instance）

**定义**：一个独立的对话实例，包含隔离的角色状态和历史事件。

**本质**：状态隔离容器。用户选择同一个角色+背景，可以创建多个会话实例，每个实例的角色状态、剧情进度、历史事件完全独立。

**创建方式**：
- 用户选择一个角色 → 创建新会话实例
- 系统初始化：
  - 复制角色定义 → 创建该实例的独立角色状态
  - 初始化instance_state.json（记录角色ID、创建时间等）

**背景设定**：
- 背景是独立的、可切换的提示词模块
- 创建实例时可以选择一个背景，也可以不选
- 对话过程中可以随时切换背景
- 当前使用的背景ID记录在instance_state.json中

**核心特性**：
1. **状态隔离**：同一角色在不同实例中的状态完全独立
2. **可重玩**：同样的角色+背景可以创建多个实例，体验不同走向
3. **可暂停/继续**：一个实例可以有多个会话（Session），支持暂停后继续

**示例**：
```
实例A：角色"黑帮老大" + 背景"废土复仇记"
→ 第3点选择"杀死仇人" → 走向暴力结局

实例B：同一角色 + 同一背景（重玩）
→ 第3点选择"放过仇人" → 走向救赎结局

两个实例完全独立，互不影响
```

---

## 核心需求

### 需求1：主线剧情的执行与遵守

**问题**：
- AI执行主线不完整：背景设定中定义了10个剧情节点，AI执行到第3个就不继续
- AI自主编创偏离主线：AI经常编造与主线无关的剧情，导致故事发展与预期不符

**期望**：
- AI能持续按照主线剧情节点推进故事
- AI可以在细节上自由发挥，但大方向要贴合主线大纲
- 允许AI在大纲点内自由演绎（例如"开枪"这个点可以有不同走向：死、伤、逃）

**现实约束**：
- 承认AI无法100%自动遵守主线
- 用户需要在输入框中临时干预剧情
- 系统应尽可能提高AI遵守主线的概率

**解决方案**：见 [DESIGN_OVERVIEW.md](DESIGN_OVERVIEW.md) 第4章"导演模块（Director）"

---

### 需求2：人格的丰富性与成长

**问题**：
- 人格过于简单：角色人格扁平，缺乏内在冲突和复杂性，行为模式单一
- 人格缺乏成长：角色人格在长对话中保持静态，重要事件后没有相应成长
- AI处理能力有限：人格维度过多时AI表现混乱、自相矛盾

**期望**：
- 角色人格丰富、有深度、有内在冲突
- 角色人格能随剧情发展而成长和变化
- 在AI处理能力约束下，实现尽可能丰富的人格表现

**AI处理能力上限**（根据经验）：
- 二元对立（如：爱/恨）最多3组
- 三元张力（如：忠诚/背叛/中立）最多2组

**解决方案**：见 [DESIGN_OVERVIEW.md](DESIGN_OVERVIEW.md) 第6章"角色人格机制"

---

### 需求3：长会话与跨会话的延续性

**问题**：
- 长会话失忆：对话几百轮后，AI遗忘早期重要信息和人格设定
- 跨会话失忆：暂停后再继续时，AI忘记之前会话的角色状态和事件

**期望**：
- 角色能记住历史上发生的重要事件
- 角色状态在长会话和跨会话中保持连贯
- 当用户提到历史事件时，AI能够回忆起来

**技术挑战**：
- AI的上下文窗口有限，无法把所有历史对话都放入上下文

**解决方案**：见 [DESIGN_OVERVIEW.md](DESIGN_OVERVIEW.md) 第5章"RAG检索策略"

---

## 功能需求

### 角色管理
- 创建角色：定义名称、描述、头像、初始人格设定
- 查看角色列表
- 编辑角色
- 删除角色

### 背景管理
- 创建背景：定义世界设定（一段文字）、故事主线大纲（10个关键点）
- 查看背景列表
- 编辑背景
- 删除背景

### 会话实例管理
- 创建会话实例：选择角色，可选择背景（也可以不选）
- 查看会话实例列表：显示标题、角色、当前使用的背景、创建时间、最后对话时间
- 继续会话实例：加载历史状态（角色状态、剧情进度），继续对话
- 切换背景：在对话界面可以随时切换当前使用的背景
- 删除会话实例

### 对话功能
- 发送消息：用户输入内容（对话、剧情推动、世界描述、干预指令）
- 接收消息：AI生成角色反应和叙事，流式显示
- 查看历史对话

### 维护功能
- 汇总对话：用户手动触发，生成历史事件摘要，创建新会话
- 更新记忆：用户手动触发，更新角色的成长人格

---

## 技术约束

### LLM上下文窗口有限
**约束**：无法将所有历史对话都放入上下文，需要技术手段选择性加载历史信息。

### LLM注意力机制的U型特点
**约束**：
- 头部0-4K和尾部4K信息权重较高
- 中间4K-32K信息权重中等
- 32K+区域能看到事实，但语义分析能力较弱
- 当上下文很长时，尾部信息的高权重会淹没头部信息

### LLM处理复杂人格能力有限
**约束**：超过能力上限（二元对立3组/三元张力2组）时，AI表现会混乱。

### LLM生成的不可控性
**约束**：LLM是生成式模型，无法100%控制输出，只能提高遵守概率。

### 响应时间要求
**约束**：总响应时间应控制在30秒以内。

**说明**：以上约束的应对策略见 [DESIGN_OVERVIEW.md](DESIGN_OVERVIEW.md)

---

## UI布局设计

**布局结构**：
```
┌──────────┬─────────────────────────┬──────────┐
│          │ [顶部功能栏]             │          │
│          │ - 切换会话实例           │          │
│          │ - 全局设置               │          │
│          ├─────────────────────────┤          │
│          │                         │          │
│ 左侧边栏 │                         │ 右侧边栏 │
│ (顶到底) │    对话消息区           │ (顶到底) │
│          │    - AI 回复            │          │
│ 🧠更新记忆│    - 用户消息           │ 📊角色状态│
│          │    - 流式显示           │          │
│ 📝汇总对话│                         │ 📚历史事件│
│          │                         │          │
│ 🎬拉回主线│                         │ 📖背景设定│
│          │                         │          │
│ ⚙️ 设置   │                         │          │
│          │                         │          │
│ ...     │                         │ ...     │
│          │                         │          │
│          ├─────────────────────────┤          │
│          │ [用户输入框]   [发送]    │          │
└──────────┴─────────────────────────┴──────────┘
```

**关键特性**：
- **三个区域（左、中、右）都是从顶到底**
- 中间区域内部分为三部分：
  - 上：顶部功能栏（高度小）
  - 中：对话消息区（高度大，可滚动）
  - 下：用户输入框（高度小，与顶部功能栏面积相同）
- 中间区域占比约 50%
- 左右侧边栏可伸缩，功能按钮垂直排列

---

## 基础功能清单

### 核心功能（必须有）
1. **角色管理** - CRUD（创建、读取、更新、删除）
2. **背景管理** - CRUD
3. **会话实例管理** - CRUD
4. **对话功能** - 发送消息、接收流式响应

### 基础功能（必须有）
5. **角色导入导出**
   - 导出格式：JSON（PersonaLab 格式）
   - 导入格式：JSON（PersonaLab 格式）
   - 未来扩展：兼容其他格式（如 CharacterAI/SillyTavern 格式）

6. **背景导入导出**
   - 导出格式：JSON（PersonaLab 格式）
   - 导入格式：JSON（PersonaLab 格式）

7. **会话实例导出**
   - 导出完整对话历史（JSONL → 可读格式，如 Markdown/TXT）
   - 用于分享或备份

8. **角色状态查看**（用户端）
   - 查看当前角色的两层人格状态（base_persona + evolved_persona）
   - 只读模式，不可编辑（evolved_persona 由 AI 自动维护）

9. **角色编辑**（用户端）
   - 编辑全局角色库中的角色初始设定（initial_profile）
   - 这是"角色管理"的基础功能（CRUD 的 U）
   - 注意：不能编辑会话实例中的角色状态（那个属于实例）

---

## 后台管理端功能

### 必备功能

1. **待处理事件管理**
   - 查看所有 `pending_events`（事件写入失败的暂存文件）
   - 批量重试/删除

2. **角色状态维护历史**
   - 查看维护记录（每次维护的时间、会话ID）
   - 查看每次维护的输入和输出（旧evolved_persona vs 新evolved_persona）
   - 回滚到历史版本（可选功能）

3. **系统配置**
   - LLM API 配置（OpenAI/Claude API Key、Base URL）
   - Embedding 模型配置
   - Prompt 模板管理（V2 功能，V1 先固定）

4. **数据统计与监控**
   - 会话实例数量、总对话轮数
   - 事件库大小（每个实例的事件数）
   - 系统性能监控（API 响应时间、LLM 调用耗时、RAG 检索耗时）
   - 错误日志查看

5. **数据管理**
   - 清理过期数据（可选）
   - 备份与恢复
   - 事件库优化（重建索引等）

---

## 需求澄清记录（2025-10-14）

### 1. 用户输入处理

**决策**：统一处理，不做类型区分

用户输入可能包含多种类型（对话、剧情推动、世界描述、干预指令），系统不做预处理分类，由 AI 自动推断意图。

**设计影响**：
- 前端只需要一个输入框
- 后端统一处理用户输入，不做类型判断

---

### 2. `[PROGRESS]` 标记机制的容错

**决策**：允许 AI 自动判断剧情进度，信任 AI 的输出

**容错策略**：
- AI 不必每轮都输出 `[PROGRESS]` 标记
- 连续 3 轮未输出时，触发 RAG 兜底机制
- 不需要验证机制（如连续 2 次确认），直接采信 AI 的判断
- 状态可以灵活跳转（不强制 `pending → in_progress → completed` 顺序）

**失败时的处理**：
- 如果 AI 判断错误，用户可以通过干预指令手动纠正
- 兜底机制会在 3 轮后自动拉回主线

---

### 3. 角色状态维护的手动触发

**决策**：提供手动触发功能，允许用户在需要时立即更新角色记忆

**实现方式**：
- UI 位置：对话界面的左侧或右侧功能区（垂直排列）
- 交互方式：点击 "🧠 更新记忆" 按钮
- 执行方式：同步执行，显示加载状态（约 6-11 秒）
- 反馈方式：完成后 Toast 通知用户

**性能评估**：
```
角色状态维护任务耗时：
- 加载当前角色状态: ~50ms
- 加载当前会话对话: ~100ms
- LLM 重新生成 evolved_persona: ~5-10s
- 写入新角色状态: ~50ms
总耗时：~6-11 秒（主要是 LLM 调用）
```

用户可接受此等待时间，因为是用户主动触发。

---

### 4. 故事主线大纲的灵活性

**决策**：
- 大纲点数量**不固定**，由用户自由编写（可以是 5 个、10 个、20 个或更多）
- 大纲是**建议路线**，不是强制路线
- 完成全部大纲点后，进入**自由对话模式**

**完成后的行为**：
- 当全部大纲点完成时：
  - 导演模块不再触发 RAG 兜底
  - AI 可以任意发挥，无主线约束

---

### 5. 导演模块的"拉回主线"功能

**决策**：提供手动触发的"拉回主线"功能

**UI 位置**：对话界面的左侧或右侧功能区（垂直排列），按钮名称 "🎬 拉回主线"

**实现机制**：
- 用户点击按钮后，后端通过某种策略将信息插入到特定位置，影响 Prompt 组装
- 具体策略见设计文档

---

### 6. 并发与存储

**决策**：先按单用户实现，预留 SQLite 迁移

**当前方案**：
- 使用文件系统存储（JSON/JSONL）
- 不考虑并发写入冲突
- 简单的文件锁机制即可

**未来扩展**：
- 如果需要多用户支持，迁移到 SQLite 或其他轻量数据库
- 预留接口，便于未来迁移

---

### 7. 事件写入失败的暂存机制

**决策**：
- 异步写入事件，失败时暂存到临时文件
- 通过 WebSocket 通知用户写入失败
- 后台管理端提供批量重试功能

**数据结构**：
```
data/
├── instances/
│   └── {instance_id}/
│       ├── pending_events/          ← 待写入事件暂存目录
│       │   ├── pending_001.json
│       │   ├── pending_002.json
│       │   └── ...
│       ├── metadata.json
│       ├── character_state.json
│       └── sessions/
```

---

**文档结束**
