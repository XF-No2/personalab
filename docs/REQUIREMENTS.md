# PersonaLab 需求文档

**文档版本**: v2.1
**创建日期**: 2025-10-14
**最后更新**: 2025-10-14

---

## 项目定位

PersonaLab是一个AI角色对话平台，类似Silly Tavern系统。支持用户与AI角色进行长篇、高一致性、角色可成长的互动叙事体验。

---

## 基本概念

### 角色（Character）

**定义**：存储在全局角色库中的角色模板，包含：
- 基础信息：名称、描述、头像
- 初始人格设定：性格特征、背景故事、核心动机

**特性**：
- 一个角色可以被多个会话实例使用
- 在不同会话实例中的状态完全独立

### 背景（Background）

**定义**：存储在全局背景库中的故事设定，包含：
- **世界设定**：世界观描述、世界规则、初始场景（一段完整的文字描述）
- **故事主线大纲**：预定义的10个关键剧情点，提供故事发展的整体方向

**示例**：
```
背景名称：废土复仇记

世界设定：
核战后的废土世界，资源匮乏，强者为王。幸存者聚集在几个主要据点，
帮派之间争夺控制权。你是一个被背叛的前帮派老大，现在要复仇。

故事主线大纲：
1. 发现背叛者的线索
2. 潜入敌人据点
3. 与仇人对峙
4. 做出关键选择（杀/放/合作）
5. 应对选择的后果
...（共10个关键点）
```

### 会话实例（Conversation Instance）

**定义**：一个独立的对话实例，包含隔离的角色状态和历史事件。

**本质**：状态隔离容器。用户选择同一个角色+背景，可以创建多个会话实例，每个实例的角色状态、剧情进度、历史事件完全独立。

**创建方式**：
- 用户选择一个角色 + 一个背景 → 创建新会话实例
- 系统初始化：
  - 复制角色定义 → 创建该实例的独立角色状态
  - 加载背景的故事主线大纲
  - 初始化剧情状态（从第1点开始）

**核心特性**：
1. **状态隔离**：同一角色在不同实例中的状态完全独立
2. **可重玩**：同样的角色+背景可以创建多个实例，体验不同走向
3. **可暂停/继续**：一个实例可以有多个会话（Session），支持暂停后继续

**示例**：
```
实例A：角色"黑帮老大" + 背景"废土复仇记"
→ 第3点选择"杀死仇人" → 走向暴力结局

实例B：同一角色 + 同一背景（重玩）
→ 第3点选择"放过仇人" → 走向救赎结局

两个实例完全独立，互不影响
```

**数据库字段**：`instance_id`

---

## 核心需求

### 需求1：主线剧情的执行与遵守

**问题**：
- AI执行主线不完整：背景设定中定义了10个剧情节点，AI执行到第3个就不继续
- AI自主编创偏离主线：AI经常编造与主线无关的剧情，导致故事发展与预期不符

**期望**：
- AI能持续按照主线剧情节点推进故事
- AI可以在细节上自由发挥，但大方向要贴合主线大纲
- 允许AI在大纲点内自由演绎（例如"开枪"这个点可以有不同走向：死、伤、逃）

**现实约束**：
- 承认AI无法100%自动遵守主线
- 用户需要在输入框中临时干预剧情
- 系统应尽可能提高AI遵守主线的概率

**设计方案：导演模块（Director）**

导演模块负责剧情控制，采用**三层控制机制**：

#### 1. 静态约束：主线大纲（Prompt头部4K）

将全部10个主线大纲点放入Prompt头部4K区域：
```json
{
  "story_outline": [
    {"index": 1, "content": "发现背叛者的线索", "status": "completed"},
    {"index": 2, "content": "潜入敌人据点", "status": "completed"},
    {"index": 3, "content": "与仇人对峙", "status": "in_progress"},
    {"index": 4, "content": "做出关键选择", "status": "pending"},
    ...
  ],
  "current_plot_index": 3
}
```
- 使用JSON格式提升头部权重
- 全量存储（不清理前面的大纲点，保持上下文完整）
- 标记当前进度，引导AI推进

#### 2. 动态引导：剧情状态实时更新

AI每次回复时，在内容中输出剧情进度判断：
```
AI回复示例：
"你的枪口对准了他，他眼中闪过一丝恐惧..." [PROGRESS:3:in_progress]
```

**格式**：`[PROGRESS:{大纲点索引}:{status}]`
- status可选值：`completed`（已完成）、`in_progress`（进行中）、`pending`（待进行）

**后端处理**：
1. 正则扫描AI回复，查找`[PROGRESS:X:status]`标记（无论位置）
2. 如果找到：
   - 更新剧情状态（Prompt头部JSON）
   - 记录更新轮次
   - 从用户看到的回复中删除此标记
3. 如果没找到：保持上次状态不变

**容错机制**：
- AI不必每次都输出，3轮内出现即可
- 标记可以出现在回复任何位置（开头/中间/结尾）
- 后端正则扫描是文本处理，性能影响可忽略（<1ms）

#### 3. 兜底机制：RAG拉回主线

当AI连续3轮都没输出`[PROGRESS]`标记时，触发兜底机制：

**分层检索策略**（利用历史剧情经验）：

```python
if current_turn - last_progress_update_turn >= 3:
    # AI可能跑偏，用当前大纲点作为查询
    query = f"故事大纲第{current_plot_index}点：{outline_content}"

    # 第一次检索：当前实例的事件（高权重，当前剧情事实）
    events_current = chroma_collection.query(
        query_embeddings=embed(query),
        where={
            "instance_id": current_instance,
            "character_id": current_character,
            "background_id": current_background
        },
        n_results=15
    )

    # 第二次检索：其他实例的事件（低权重，剧情经验参考）
    events_others = chroma_collection.query(
        query_embeddings=embed(query),
        where={
            "$and": [
                {"instance_id": {"$ne": current_instance}},
                {"character_id": current_character},
                {"background_id": current_background}
            ]
        },
        n_results=5
    )

    # 分层注入Prompt
    prompt_inject = f"""
    【当前剧情事件】（这些是当前剧情中实际发生的事件）
    {format_events(events_current)}

    【剧情经验参考】（其他剧情中的类似情节，仅供参考剧情走向，不代表当前剧情的事实）
    {format_events(events_others)}
    """
```

**设计思路**：
- **需求矛盾**：既想利用历史剧情经验帮助AI理解剧情走向，又不想历史事件污染当前剧情的内部一致性
- **解决方案**：分层展示，明确区分"当前剧情事实"和"其他剧情经验参考"
- **权重分配**：当前实例15条（高权重），其他实例5条（低权重）
- **Prompt指示**：在系统指令中明确告诉AI，"剧情经验参考"只是帮助理解剧情方向，不要当作当前剧情的事实

**效果**：
- 平时AI自由发挥，自己判断剧情进度
- 当AI跑偏时，分层检索提供支撑：
  - 当前实例的历史事件：提醒AI已经发生了什么
  - 其他实例的经验：参考类似剧情应该怎么走
- 像一根绳子，拉住AI不要偏离太远，同时利用历史经验增强剧情连贯性

### 需求2：人格的丰富性与成长

**问题**：
- 人格过于简单：角色人格扁平，缺乏内在冲突和复杂性，行为模式单一
- 人格缺乏成长：角色人格在长对话中保持静态，重要事件后没有相应成长
- AI处理能力有限：人格维度过多时AI表现混乱、自相矛盾

**期望**：
- 角色人格丰富、有深度、有内在冲突
- 角色人格能随剧情发展而成长和变化
- 在AI处理能力约束下，实现尽可能丰富的人格表现

**AI处理能力上限**（根据经验）：
- 二元对立（如：爱/恨）最多3组
- 三元张力（如：忠诚/背叛/中立）最多2组

**设计方案（借鉴Letta/MemGPT的记忆架构）**：

采用**三层记忆架构**：

#### Core Memory（核心记忆）
- **内容**：角色当前完整的人格画像（JSON格式）
- **位置**：Prompt头部4K区域
- **维护**：每10轮对话触发维护任务
  - 使用LLM整合"旧Core Memory + 最近10轮对话 + 状态变化事件"
  - 重新生成完整的Core Memory
- **人格复杂度**：控制在AI处理能力范围内（二元对立3组/三元张力2组）

#### Archival Memory（归档记忆）
- **内容**：历史人格变化事件
- **存储**：向量数据库（Chroma）
- **写入时机**：只在角色状态发生变化时写入
- **写入方式**：异步写入，不阻塞响应

#### Recall Memory（工作记忆）
- **内容**：最近对话历史
- **位置**：Prompt中间区域（4K-32K）

### 需求3：长会话与跨会话的延续性

**问题**：
- 长会话失忆：对话几百轮后，AI遗忘早期重要信息和人格设定
- 跨会话失忆：暂停后再继续时，AI忘记之前会话的角色状态和事件

**期望**：
- 角色能记住历史上发生的重要事件
- 角色状态在长会话和跨会话中保持连贯
- 当用户提到历史事件时，AI能够回忆起来

**技术挑战**：
- AI的上下文窗口有限，无法把所有历史对话都放入上下文

**设计方案（基于向量数据库RAG，优化Silly Tavern的世界书机制）**：

#### 检索触发机制（Conversational RAG）

**日常对话场景**（用户主动提到历史事件）：

使用LLM将"当前用户输入 + 最近5-10条对话历史"重新表述为独立的查询语句：
```
用户输入："你还记得我们在据点的那次冲突吗？"
最近对话：（5-10条）

LLM重新表述为独立查询：
"据点冲突事件，涉及主角与某人的对抗"
```

用这个查询进行向量检索，**只检索当前实例**的历史事件（20条）：
```python
events = chroma_collection.query(
    query_embeddings=embed(query),
    where={"instance_id": current_instance},
    n_results=20
)
```

**优势**：
- 相比Silly Tavern的关键词匹配，语义检索不需要精确命中关键词
- 覆盖范围与世界书相同（考虑对话上下文），但检索方式更智能

#### 检索结果处理
- 检索结果放入Prompt的32K+区域（扩展区域）
- 该区域AI能看到事实信息，但语义分析能力较弱
- 适合放置大量历史事件供AI参考

#### 实例隔离与跨实例检索

**实例隔离**（日常对话）：
- 日常对话的RAG检索只检索当前实例的事件
- 检索时必须过滤`instance_id`，避免不同实例的事件混淆
- 保证当前剧情的内部一致性

**跨实例检索**（导演模块兜底）：
- 只在导演模块兜底机制中，才进行跨实例检索
- 分层展示：当前实例事件（15条）+ 其他实例经验（5条）
- 明确标记来源，避免污染当前剧情

#### 跨会话延续
- 新会话（Session）加载会话实例的Core Memory和历史事件
- 角色状态和剧情进度自动延续

---

## 功能需求

### 角色管理
- 创建角色：定义名称、描述、头像、初始人格设定
- 查看角色列表
- 编辑角色
- 删除角色

### 背景管理
- 创建背景：定义世界设定（一段文字）、故事主线大纲（10个关键点）
- 查看背景列表
- 编辑背景
- 删除背景

### 会话实例管理
- 创建会话实例：选择角色和背景，初始化角色状态和剧情状态
- 查看会话实例列表：显示标题、角色、背景、创建时间、最后对话时间
- 继续会话实例：加载历史状态（角色状态、剧情进度），继续对话
- 删除会话实例

### 对话功能
- 发送消息：用户输入内容（对话、剧情推动、世界描述、干预指令）
- 接收消息：AI生成角色反应和叙事，流式显示
- 查看历史对话

---

## 技术约束与对应设计

### LLM上下文窗口有限
**约束**：无法将所有历史对话都放入上下文，需要技术手段选择性加载历史信息。

**应对**：使用向量数据库RAG检索历史事件，Core Memory存储当前状态。

### LLM注意力机制的U型特点
**约束**：
- 头部0-4K和尾部4K信息权重较高
- 中间4K-32K信息权重中等
- 32K+区域能看到事实，但语义分析能力较弱
- 当上下文很长时，尾部信息的高权重会淹没头部信息

**应对（Prompt区域分配策略）**：
- **头部0-4K**：
  - 系统指令
  - Core Memory（完整人格画像）
  - 剧情状态（当前进度标记）
  - 全部主线大纲（10个点）
  - 使用JSON格式提升权重
- **中间4K-32K**：
  - 背景世界设定
  - 最近对话（Recall Memory）
- **32K+区域**：
  - RAG检索的20条历史事件（Archival Memory）
  - 导演模块RAG拉回的剧情相关事件
- **尾部4K**：用户最新输入

### LLM处理复杂人格能力有限
**约束**：超过能力上限（二元对立3组/三元张力2组）时，AI表现会混乱。

**应对**：Core Memory中的人格描述控制在该复杂度范围内。

### LLM生成的不可控性
**约束**：LLM是生成式模型，无法100%控制输出，只能提高遵守概率。

**应对**：
- 通过头部JSON格式的强约束提高遵守概率
- 导演模块三层控制机制（静态约束 + 动态引导 + RAG兜底）
- 接受用户需要临时干预的现实

### 响应时间要求
**约束**：总响应时间应控制在30秒以内。

**应对**：
- 使用流式输出改善等待体验
- 异步并行加载（Core Memory、历史事件、最近对话）
- 事件写入异步执行，不阻塞响应
- RAG检索设置超时保护（1.5秒）

### 定期维护机制
**设计**：统一的定期维护任务入口，每10轮触发
- 使用LLM整合"旧Core Memory + 最近10轮对话 + 状态变化事件"重新生成完整的Core Memory
- 清理Recall Memory（保留最近20轮对话）
- 其他维护任务统一管理

---

## 导演模块（Director）完整机制总结

**职责**：控制剧情推进，确保AI不偏离主线大纲

**三层控制**：
1. **静态约束**：全量主线大纲放头部4K，JSON格式，标记当前进度
2. **动态引导**：AI每次回复输出`[PROGRESS:X:status]`，后端正则扫描更新状态
3. **RAG兜底**：连续3轮未更新时，用当前大纲点查询RAG，注入相关事件拉回主线

**效果**：像一根绳子，允许AI在细节上自由发挥，但拉住AI不要偏离主线方向

---

**文档结束**
